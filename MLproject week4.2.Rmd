---
<center> <h1> </h1>
<h1>Analysis of Auto transmisson effect on average MPG<h1>

<h2><I> by Tim Jones</I><h2>

<h4> 26th June 2017</h4>
<br></center>
---


---
<center> <h1>""</h1><center>
author: "Tim Jones"
date: "11 August 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This project will investigate machine learning methods for predicting the whether exercises have been completed in the correct form using data obtained from activity monitoring devices such as the Jawbone UP and Fitbit. 

The provided training data will be imported, tidied up and used to train several predictive models which will use the Random forest technique to train a predictive model and test its accuracy on a withheld chunk of the training data.

## Methodology

### Initiate packages required and set seed
```{r message=FALSE, warning=F}
###packages required
library("dplyr")
library("caret")

###set repeatable seed
set.seed(8182)
```

## Load data from file, set data partition to create test and training sets
```{r}
Fdata<-read.csv("pml-training.csv",stringsAsFactors = F, na.strings = c("","NA"))

### impute values into the NA ones from aggregate window summaries.

incNA<-sapply(Fdata[Fdata$new_window=="no",],function(x) any(which(is.na(x),arr.ind = TRUE)))
naCols<-colnames(Fdata)[incNA]
imputedFValues<-Fdata[Fdata$new_window=="yes",names(Fdata) %in% c(naCols,"raw_timestamp_part_1")]
compValues<-Fdata[Fdata$new_window=="no",!names(Fdata) %in% naCols]

### merge the suummary window data into each individual row       
mergeData<-merge(compValues,imputedFValues,by.x = "raw_timestamp_part_1",by.y = "raw_timestamp_part_1")

### 75% training 25% test
inTrain<-createDataPartition(mergeData$classe,p=0.75)[[1]]

TrainPredictors<-mergeData[inTrain,-60]
TrainOutcome<-mergeData[inTrain,60]
TestPredictors<-mergeData[-inTrain,-60]
TestOutcome<-mergeData[-inTrain,60]


###include only columns that do not contain #DIV/0! in the training data

TrainPredictors<-TrainPredictors[,-5]
trainCol<-sapply(X = TrainPredictors,FUN=function(x) !any(which(x=="#DIV/0!")))
TrainPredictors<-TrainPredictors[,names(trainCol[trainCol==T])]


### set String variables to Factors & remove data variable
TrainPredictors$user_name<-as.factor(TrainPredictors$user_name)
TrainPredictors$new_window<-as.factor(TrainPredictors$new_window)
```

We will use a Radom Forest Model to predict which exercise is being performed and will train it on the 75% imputed data.

```{r cache=T}
### train Random Forest Model
ModelRF<-caret::train(TrainPredictors,TrainOutcome,method = "rf")
```


use the trained model to make predictions on the training data and draw a confusion matrix, this shows 100% accuracy on the training samples.
```{r}
trainval1<-predict(ModelRF,TrainPredictors)
confusionMatrix(as.factor(TrainOutcome),trainval1)
```

###prepare test data in similar manner to training data

```{r}
TestPredictors<-TestPredictors[,-5]
testCol<-sapply(X = TestPredictors,FUN=function(x) !any(which(x=="#DIV/0!")))
TestPredictors<-TestPredictors[,names(testCol[testCol==T])]
TestPredictors$user_name<-as.factor(TestPredictors$user_name)
TestPredictors$new_window<-as.factor(TestPredictors$new_window)
```

use cross validation data to provide an out of sample prediction, 100% accuracy on cross validation samples. 0% out of sample error!

```{r}
cval1<-predict(ModelRF,TestPredictors)
confusionMatrix(as.factor(TestOutcome),cval1)

```


